{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "row_ind, col_ind = linear_sum_assignment(cost)\n",
    "cost[row_ind, col_ind].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1, 0, 2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost1 = np.array([[4, 0, 0], [2, 0, 0], [1, 0, 0]])\n",
    "row_ind, col_ind = linear_sum_assignment(cost1)\n",
    "cost[row_ind, col_ind].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show GPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import subprocess\n",
    "import csv\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Gpu:\n",
    "    uuid: str\n",
    "    name: str\n",
    "    utilization: float\n",
    "\n",
    "def fetch():\n",
    "    servers = ['gpu3', 'gpu4', 'gpu5']\n",
    "    gpus = []\n",
    "\n",
    "    for server in servers:\n",
    "        result = subprocess.run(\n",
    "            f\"ssh {server} nvidia-smi --query-gpu=uuid,gpu_name,utilization.gpu --format=csv,noheader\".split(' '), \n",
    "            stdout = subprocess.PIPE\n",
    "        ).stdout.decode('utf-8').splitlines()\n",
    "        \n",
    "        for stat in csv.reader(result, delimiter=','):\n",
    "            gpus.append(Gpu(uuid=stat[0].strip('GPU-'), name=stat[1], utilization=float(stat[2].strip('%'))))\n",
    "\n",
    "    return gpus\n",
    "\n",
    "for gpu in fetch():\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Docker Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Error': None, 'StatusCode': 0}\n"
     ]
    }
   ],
   "source": [
    "import docker\n",
    "client = docker.from_env()\n",
    "\n",
    "container = client.containers.run(\n",
    "    name = \"tensorflow-mnist-105\",\n",
    "    image=\"horovod/horovod:latest\", \n",
    "    command=\"horovodrun -np 2 -H localhost:2 python ./tensorflow2/tensorflow2_keras_mnist.py\",\n",
    "    shm_size=\"1G\",\n",
    "    detach=True,\n",
    "    environment={\n",
    "        \"NVIDIA_VISIBLE_DEVICES\": \"0,1\",\n",
    "    }\n",
    ")\n",
    "status = container.wait()\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Error': None, 'StatusCode': 2}\n"
     ]
    }
   ],
   "source": [
    "container = client.containers.run(\n",
    "    name = \"tensorflow-mnist-106\",\n",
    "    image=\"horovod/horovod:latest\", \n",
    "    command=\"horovodrun -np 2 -H localhost:2 python ./tensorflow2/tensorflow2_keras.py\",\n",
    "    shm_size=\"1G\",\n",
    "    detach=True,\n",
    "    environment={\n",
    "        \"NVIDIA_VISIBLE_DEVICES\": \"0,1\",\n",
    "    }\n",
    ")\n",
    "\n",
    "status = container.wait()\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,2,3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = {\"server\": \"gpu3\", \"gpus\": [1,2,3]}\n",
    "\n",
    "\",\".join([str(gpu) for gpu in gpus['gpus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('schedulearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d076e4b4733baeb8f06e5fb62baae335452315d319e1f6c2ff42bd4b0c75ec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
